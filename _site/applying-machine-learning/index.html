<!DOCTYPE html>
<head>
    <meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="description" content="Evaluating machine learning algorithms, training set, cross validation set, test set, bias, variance, learning curves and improving algorithm performance.">
<meta name="keywords" content="machine_learning,  machine_learning">
<title>Applying Machine Learning  | Machine Learning, Deep Learning, and Computer Vision</title>
<link rel="stylesheet" href="/css/syntax.css">


<link rel="stylesheet" type="text/css" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.5.0/css/font-awesome.min.css">
<!--<link rel="stylesheet" type="text/css" href="css/bootstrap.min.css">-->
<link rel="stylesheet" href="/css/modern-business.css">
<link rel="stylesheet" href="/css/lavish-bootstrap.css">
<link rel="stylesheet" href="/css/customstyles.css">
<link rel="stylesheet" href="/css/theme-green.css">

<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/2.1.4/jquery.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery-cookie/1.4.1/jquery.cookie.min.js"></script>
<script src="/js/jquery.navgoco.min.js"></script>


<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.4/js/bootstrap.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/anchor-js/2.0.0/anchor.min.js"></script>
<script src="/js/toc.js"></script>
<script src="/js/customscripts.js"></script>

<link rel="shortcut icon" href="http://res.cloudinary.com/ritchieng/image/upload/v1468818827/ritchieng.com/favicon_p13h5n.ico">

<!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
<!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
<!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
<script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
<![endif]-->

<link rel="alternate" type="application/rss+xml" title="" href="http://www.ritchieng.com/feed.xml">




 
    <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script>
        $(document).ready(function() {
            // Initialize navgoco with default options
            $("#mysidebar").navgoco({
                caretHtml: '',
                accordion: true,
                openClass: 'active', // open
                save: false, // leave false or nav highlighting doesn't work right
                cookie: {
                    name: 'navgoco',
                    expires: false,
                    path: '/'
                },
                slide: {
                    duration: 400,
                    easing: 'swing'
                }
            });

            $("#collapseAll").click(function(e) {
                e.preventDefault();
                $("#mysidebar").navgoco('toggle', false);
            });

            $("#expandAll").click(function(e) {
                e.preventDefault();
                $("#mysidebar").navgoco('toggle', true);
            });

        });

    </script>
    <script>
        $(function () {
            $('[data-toggle="tooltip"]').tooltip()
        })
    </script>
    
    <!-- Begin Jekyll SEO tag v1.3.1 -->
<title>Applying Machine Learning</title>
<meta property="og:title" content="Applying Machine Learning" />
<meta name="description" content="I am Ritchie Ng, a machine learning engineer specializing in deep learning and computer vision. Check out my code guides and keep ritching for the skies!" />
<meta property='og:description' content="I am Ritchie Ng, a machine learning engineer specializing in deep learning and computer vision. Check out my code guides and keep ritching for the skies!" />
<link rel="canonical" href="http://www.ritchieng.com/applying-machine-learning/" />
<meta property='og:url' content='http://www.ritchieng.com/applying-machine-learning/' />
<meta property="article:publisher" content="ritchiengz" />
<meta property="fb:app_id" content="1736736559921494" />
<script type="application/ld+json">
  {
    "@context" : "http://schema.org",


    "@type" : "WebPage",

    "headline": "Applying Machine Learning",

    "description": "I am Ritchie Ng, a machine learning engineer specializing in deep learning and computer vision. Check out my code guides and keep ritching for the skies!",

    "logo": "http://www.ritchieng.com/http://res.cloudinary.com/ritchieng/image/upload/v1468818828/ritchieng.com/company_logo_big_ycwbod.png",


    "url" : "http://www.ritchieng.com/applying-machine-learning/"
  }
</script>
<!-- End Jekyll SEO tag -->
</head>
<body>
<!-- Navigation -->
<nav class="navbar navbar-inverse navbar-fixed-top">
    <div class="container topnavlinks">
        <div class="navbar-header">
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="/">&nbsp;<span class="projectTitle"> Ritchie Ng</span></a>
        </div>
        <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
            <ul class="nav navbar-nav navbar-right">
                <!-- entries without drop-downs appear here -->
                
                
                
                <li><a href="/programming-languages/">Languages</a></li>
                
                
                
                <li><a href="/machine-learning-resources/">Machine Learning</a></li>
                
                
                
                <li><a href="/news/">Blog</a></li>
                
                
                
                <li><a href="/search/">Search</a></li>
                
                
                
                <!-- entries with drop-downs appear here -->
                <!-- conditional logic to control which topnav appears for the audience defined in the configuration file.-->
                
                

                <!--comment out this block if you want to hide search-->
                <!--<li>-->
                    <!--&lt;!&ndash;start search&ndash;&gt;-->
                    <!--<div id="search-demo-container">-->
                        <!--<input type="text" id="search-input" placeholder="search...">-->
                        <!--<ul id="results-container"></ul>-->
                    <!--</div>-->
                    <!--<script src="/js/jekyll-search.js" type="text/javascript"></script>-->
                    <!--<script type="text/javascript">-->
                            <!--SimpleJekyllSearch.init({-->
                                <!--searchInput: document.getElementById('search-input'),-->
                                <!--resultsContainer: document.getElementById('results-container'),-->
                                <!--dataSource: '/search.json',-->
                                <!--searchResultTemplate: '<li><a href="{url}" title="Applying Machine Learning">{title}</a></li>',-->
                    <!--noResultsText: 'No results found.',-->
                            <!--limit: 10,-->
                            <!--fuzzy: true,-->
                    <!--})-->
                    <!--</script>-->
                    <!--end search-->
                </li>
            </ul>
        </div>
        </div>
        <!-- /.container -->
</nav>
<!-- Page Content -->
<div class="container">
    <div class="col-lg-12">&nbsp;</div>
    <!-- Content Row -->
    <div class="row">
        <!-- Sidebar Column -->
        <div class="col-md-3">

          












<ul id="mysidebar" class="nav">
    <li class="sidebarTitle">Machine Learning </li>
    
    
    
    <li>
        <a href="#">Machine Learning Resources</a>
        <ul>
            
            
            
            <li><a href="/machine-learning-resources/">Online Resources</a></li>
            
            
            
            
            
            
            <li><a href="/machine-learning/journals-library/">Journal Library</a></li>
            
            
            
            
            
            
            <li><a href="/machine-learning/datasets">Datasets for Machine Learning</a></li>
            
            
            
            
        </ul>
        
        
    
    <li>
        <a href="#">Machine Learning and Econometrics</a>
        <ul>
            
            
            
            <li><a href="/machine-learning/econometrics/resources">Resources</a></li>
            
            
            
            
        </ul>
        
        
    
    <li>
        <a href="#">Supervised Learning Theory</a>
        <ul>
            
            
            
            <li><a href="/machine-learning/">Overview</a></li>
            
            
            
            
            
            
            <li><a href="/one-variable-linear-regression/">One Variable Linear Regression</a></li>
            
            
            
            
            
            
            <li><a href="/linear-algebra-machine-learning/">Linear Algebra</a></li>
            
            
            
            
            
            
            <li><a href="/multi-variable-linear-regression/">Multiple Variable Linear Regression</a></li>
            
            
            
            
            
            
            <li><a href="/logistic-regression/">Logistic Regression</a></li>
            
            
            
            
            
            
            <li><a href="/neural-networks-representation/">Neural Networks (Representation)</a></li>
            
            
            
            
            
            
            <li><a href="/neural-networks-learning/">Neural Networks (Learning)</a></li>
            
            
            
            
            
            
            <li class="active"><a href="/applying-machine-learning/">Applying Machine Learning</a></li>
            
            
            
            
            
            
            <li><a href="/machine-learning-systems-design/">Machine Learning Systems Design</a></li>
            
            
            
            
            
            
            <li><a href="/machine-learning-svms-support-vector-machines/">Support Vector Machines</a></li>
            
            
            
            
        </ul>
        
        
    
    <li>
        <a href="#">Unsupervised Learning Theory</a>
        <ul>
            
            
            
            <li><a href="/machine-learning-unsupervised-learning/">Unsupervised Learning</a></li>
            
            
            
            
            
            
            <li><a href="/machine-learning-dimensionality-reduction/">Dimensionality Reduction</a></li>
            
            
            
            
            
            
            <li><a href="/machine-learning-anomaly-detection/">Anomaly Detection</a></li>
            
            
            
            
            
            
            <li><a href="/machine-learning-recommender-systems/">Recommender Systems</a></li>
            
            
            
            
            
            
            <li><a href="/machine-learning-large-scale/">Large Scale Machine Learning</a></li>
            
            
            
            
            
            
            <li><a href="/machine-learning-photo-ocr/">Photo OCR</a></li>
            
            
            
            
        </ul>
        
        
    
    <li>
        <a href="#">Reinforcement Learning Theory</a>
        <ul>
            
            
            
            <li><a href="/machine-learning-markov-decision-processes/">Markov Decision Processes</a></li>
            
            
            
            
            
            
            <li><a href="/machine-learning-reinforcement-learning/">Reinforcement Learning</a></li>
            
            
            
            
            
            
            <li><a href="/machine-learning-game-theory/">Game Theory</a></li>
            
            
            
            
        </ul>
        
        
    
    <li>
        <a href="#">Deep Learning Theory</a>
        <ul>
            
            
            
            <li><a href="/machine-learning/deep-learning/terms/">Deep Learning Terms</a></li>
            
            
            
            
            
            
            <li><a href="/machine-learning/deep-learning/intro/">Deep Learning Intro</a></li>
            
            
            
            
            
            
            <li><a href="/machine-learning/deep-learning/neural-nets/">Deep Neural Networks Intro</a></li>
            
            
            
            
            
            
            <li><a href="/machine-learning/deep-learning/convs/">Deep Convolutional Networks Intro</a></li>
            
            
            
            
        </ul>
        
        
    
    <li>
        <a href="#">Deep Learning with TensorFlow</a>
        <ul>
            
            
            
            <li><a href="/machine-learning/deep-learning/tensorflow/notmnist/">Exploring NotMNIST</a></li>
            
            
            
            
            
            
            <li><a href="/machine-learning/deep-learning/tensorflow/deep-neural-nets/">Deep Neural Networks</a></li>
            
            
            
            
            
            
            <li><a href="/machine-learning/deep-learning/tensorflow/regularization/">Regularization</a></li>
            
            
            
            
            
            
            <li><a href="/machine-learning/deep-learning/tensorflow/convnets/">Deep Convolutional Networks</a></li>
            
            
            
            
        </ul>
        
        
    
    <li>
        <a href="#">Machine Learning with Scikit-Learn</a>
        <ul>
            
            
            
            <li><a href="/machine-learning-intro-easy/">Introduction to Machine Learning</a></li>
            
            
            
            
            
            
            <li><a href="/ipython-introduction/">IPython Introduction</a></li>
            
            
            
            
            
            
            <li><a href="/machine-learning-iris-dataset/">Iris Dataset</a></li>
            
            
            
            
            
            
            <li><a href="/machine-learning-linear-regression/">Linear Regression Model</a></li>
            
            
            
            
            
            
            <li><a href="/machine-learning-evaluate-linear-regression-model/">Linear Regression Model Evaluation</a></li>
            
            
            
            
            
            
            <li><a href="/machine-learning-polynomial-regression/">Polynomial Regression</a></li>
            
            
            
            
            
            
            <li><a href="/machine-learning-multinomial-naive-bayes-vectorization/">Vectorization, Multinomial Naive Bayes Classifier and Evaluation</a></li>
            
            
            
            
            
            
            <li><a href="/machine-learning-gaussian-naive-bayes/">Gaussian Naive Bayes</a></li>
            
            
            
            
            
            
            <li><a href="/machine-learning-k-nearest-neighbors-knn/">K-nearest Neighbors (KNN) Classification Model</a></li>
            
            
            
            
            
            
            <li><a href="/machine-learning-ensemble-of-learners-adaboost/">Ensemble Learning and Adaboost</a></li>
            
            
            
            
            
            
            <li><a href="/machine-learning-decision-trees/">Decision Trees</a></li>
            
            
            
            
            
            
            <li><a href="/machine-learning-svms/">Support Vector Machines</a></li>
            
            
            
            
            
            
            <li><a href="/machine-learning-clustering-kmeans/">Clustering with KMeans</a></li>
            
            
            
            
            
            
            <li><a href="/machine-learning-dimensionality-reduction-feature-transform/">Dimensionality Reduction and Feature Transformation</a></li>
            
            
            
            
            
            
            <li><a href="/machine-learning-feature_engineering_scaling/">Feature Engineering and Scaling</a></li>
            
            
            
            
            
            
            <li><a href="/machine-learning-cross-validation/">Cross-Validation for Parameter Tuning, Model Selection, and Feature Selection</a></li>
            
            
            
            
            
            
            <li><a href="/machine-learning-efficiently-search-tuning-param/">Efficiently Searching Optimal Tuning Parameters</a></li>
            
            
            
            
            
            
            <li><a href="/machine-learning-evaluate-classification-model/">Evaluating a Classification Model</a></li>
            
            
            
            
            
            
            <li><a href="/machinelearning-one-hot-encoding/">One Hot Encoding</a></li>
            
            
            
            
            
            
            <li><a href="/machinelearning-f1-score/">F1 Score</a></li>
            
            
            
            
            
            
            <li><a href="/machinelearning-learning-curve/">Learning Curve</a></li>
            
            
            
            
        </ul>
        
        
    
    <li>
        <a href="#">Machine Learning Projects</a>
        <ul>
            
            
            
            <li><a href="/machine-learning-project-titanic-survival/">Titanic Survival Data Exploration</a></li>
            
            
            
            
            
            
            <li><a href="/machine-learning-project-boston-home-prices/">Boston House Prices Prediction and Evaluation (Model Evaluation and Prediction)</a></li>
            
            
            
            
            
            
            <li><a href="/machine-learning-project-student-intervention/">Building a Student Intervention System (Supervised Learning)</a></li>
            
            
            
            
            
            
            <li><a href="/machine-learning-project-customer-segments/">Identifying Customer Segments (Unsupervised Learning)</a></li>
            
            
            
            
            
            
            <li><a href="/machine-learning-proj-smart-cab/">Training a Smart Cab (Reinforcement Learning)</a></li>
            
            
            
            
        </ul>
        
        
        
        <!-- if you aren't using the accordion, uncomment this block:
           <p class="external">
               <a href="#" id="collapseAll">Collapse All</a> | <a href="#" id="expandAll">Expand All</a>
           </p>
           -->
    </li>
</ul>
</div>

<!-- this highlights the active parent class in the navgoco sidebar. this is critical so that the parent expands when you're viewing a page. This must appear below the sidebar code above. Otherwise, if placed inside customscripts.js, the script runs before the sidebar code runs and the class never gets inserted.-->
<script>$("li.active").parents('li').toggleClass("active");</script>
    <!-- Content Column -->
    <div class="col-md-9">
        <div class="post-header">
   <h1 class="post-title-main">Applying Machine Learning</h1>
</div>



<div class="post-content">

   
    <div class="summary">Evaluating machine learning algorithms, training set, cross validation set, test set, bias, variance, learning curves and improving algorithm performance.</div>
   

    
    
<!-- this handles the automatic toc. use ## for subheads to auto-generate the on-page minitoc. if you use html tags, you must supply an ID for the heading element in order for it to appear in the minitoc. -->
<script>
$( document ).ready(function() {
  // Handler for .ready() called.

$('#toc').toc({ minimumHeaders: 0, listType: 'ul', showSpeed: 0, headers: 'h2,h3,h4' });

/* this offset helps account for the space taken up by the floating toolbar. */
$('#toc').on('click', 'a', function() {
  var target = $(this.getAttribute('href'))
    , scroll_target = target.offset().top

  $(window).scrollTop(scroll_target - 10);
  return false
})
  
});
</script>

<div id="toc"></div>

    

    

    

    

  <h2 id="evaluating-learning-algorithm">1. Evaluating Learning Algorithm</h2>
<p>I would like to give full credits to the respective authors as these are my personal python notebooks taken from deep learning courses from Andrew Ng, Data School and Udemy :) This is a simple python notebook hosted generously through Github Pages that is on my main personal notes repository on https://github.com/ritchieng/ritchieng.github.io. They are meant for my personal review but I have open-source my repository of personal notes as a lot of people found it useful.</p>

<h3 id="a-deciding-what-to-try-next">1a. Deciding what to try next</h3>
<ul>
  <li>Suppose you have implemented regularized linear regression to predict housing prices
    <ul>
      <li>However, when you test your hypothesis your hypothesis on new set of houses, you find that it makes unacceptably large errors
        <ul>
          <li>You can do the following
            <ul>
              <li>Get more training data</li>
              <li>Smaller set of features</li>
              <li>Get additional features</li>
              <li>Try adding polynomial features</li>
              <li>Try decreasing lambda</li>
              <li>Try increasing lambda</li>
            </ul>
          </li>
          <li>Typically people randomly choose these avenues and then figure out it may not be suitable</li>
          <li>There is a simple technique to weed out avenues that are not suitable
            <ul>
              <li>Machine Learning Diagnostic
                <ul>
                  <li>Test that you can run to gain insight what is or isn’t working with a learning algorithm and gain guidance as to how best to improve its performance</li>
                  <li>Diagnostics can take time to implement, but doing so can be a very good use of your time</li>
                  <li>But it’s worth the time compared to spending months on unsuitable avenues</li>
                </ul>
              </li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h3 id="b-evaluating-a-hypothesis">1b. Evaluating a hypothesis</h3>
<ul>
  <li>In fitting parameters to your training data, you would want to lower your training error to the minimum</li>
  <li>How to tell if over-fitting?
    <ul>
      <li>You can plot for few features</li>
      <li>For many features: training/testing procedure
        <ul>
          <li>Split into 2 portions
            <ul>
              <li>Training set</li>
              <li>Test set
                <ul>
                  <li>Randomly re-order data before splitting
  <img src="https://raw.githubusercontent.com/ritchieng/machine-learning-stanford/master/w6_ml_design/test.png" alt="" /></li>
                </ul>
              </li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Training/testing procedure: linear regression
<img src="https://raw.githubusercontent.com/ritchieng/machine-learning-stanford/master/w6_ml_design/test_lg.png" alt="" /></li>
  <li>Training/testing procedure: logistic regression
<img src="https://raw.githubusercontent.com/ritchieng/machine-learning-stanford/master/w6_ml_design/test_logrg.png" alt="" /></li>
</ul>

<h3 id="c-model-selection-and-trainvalidationtest-sets">1c. Model selection and Train/Validation/Test Sets</h3>
<ul>
  <li>Model selection
    <ul>
      <li>We can create an extra parameter d which is the degree of polynomial</li>
      <li>You can measure the test error on each parameter θ
        <ul>
          <li>If you choose d = 5 and to determine how well the model generalizes, you can report test set error on Jtest(θ5)
            <ul>
              <li>But there is a problem: Jtest(θ5) is likely an optimistic estimate of generalization error
  <img src="https://raw.githubusercontent.com/ritchieng/machine-learning-stanford/master/w6_ml_design/model_selection.png" alt="" /></li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
  </li>
  <li>To address the problem, we can do the following
    <ul>
      <li>Split data into 3 categories
        <ul>
          <li>Training set</li>
          <li>Cross validation set or Validation set or CV</li>
          <li>Test set
  <img src="https://raw.githubusercontent.com/ritchieng/machine-learning-stanford/master/w6_ml_design/cv.png" alt="" /></li>
        </ul>
      </li>
      <li>You would have the following 3 errors
        <ul>
          <li>Training error</li>
          <li>Cross validation (CV) error</li>
          <li>Test error
  <img src="https://raw.githubusercontent.com/ritchieng/machine-learning-stanford/master/w6_ml_design/cv2.png" alt="" /></li>
        </ul>
      </li>
    </ul>
  </li>
  <li>We would test on cross-validation sets
    <ul>
      <li>Pick hypothesis with lowest CV error
  <img src="https://raw.githubusercontent.com/ritchieng/machine-learning-stanford/master/w6_ml_design/cv3.png" alt="" /></li>
    </ul>
  </li>
</ul>

<h2 id="bias-vs-variance">2. Bias vs Variance</h2>

<h3 id="a-diagnosing-vs-variance">2a. Diagnosing vs Variance</h3>
<ul>
  <li>When you run an algorithm and it doesn’t do as well as you hope, it typically has a high bias or high variance issue
    <ul>
      <li>High bias (underfitting)</li>
      <li>High variance (overfitting)
  <img src="https://raw.githubusercontent.com/ritchieng/machine-learning-stanford/master/w6_ml_design/variance_bias.png" alt="" /></li>
    </ul>
  </li>
  <li>Plot error against degree of polynomial, d
    <ul>
      <li>As you increase your polynomial, d,
        <ul>
          <li>Training error decreases from underfitting to overfitting</li>
          <li>Cross validation (CV) error example
            <ul>
              <li>d = 1: underfitting, high CV error</li>
              <li>d = 2: lower CV error due to better fit</li>
              <li>d = 4: overfitting, high CV error
  <img src="https://raw.githubusercontent.com/ritchieng/machine-learning-stanford/master/w6_ml_design/plot_error.png" alt="" /></li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
  </li>
  <li>How do we distinguish between a high bias or a high variance issue?
    <ul>
      <li>High Bias Error
        <ul>
          <li>High Jtrain(θ)</li>
          <li>Jtrain(θ) = Jcv(θ)</li>
        </ul>
      </li>
      <li>High Variance Error
        <ul>
          <li>Low Jtrain(θ)</li>
          <li>Jcv(θ) » Jtrain(θ)
            <ul>
              <li>Much greater as seen on the right of the graph
  <img src="https://raw.githubusercontent.com/ritchieng/machine-learning-stanford/master/w6_ml_design/distinguish_error.png" alt="" /></li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h3 id="b-regularization-and-biasvariance">2b. Regularization and Bias/Variance</h3>
<ul>
  <li>Linear regression with regularization
    <ul>
      <li>Large λ
        <ul>
          <li>High bias (underfit)</li>
        </ul>
      </li>
      <li>Small λ
        <ul>
          <li>High variance (overfit)
  <img src="https://raw.githubusercontent.com/ritchieng/machine-learning-stanford/master/w6_ml_design/lg_reg_error.png" alt="" /></li>
        </ul>
      </li>
    </ul>
  </li>
  <li>So how do we choose a good value of λ?
    <ul>
      <li>H(θ): algorithm; hypothesis</li>
      <li>J(θ): cost function; optimization objective</li>
      <li>Jtrain(θ), Jcv(θ), Jtest(θ): optimization objectives without regularization terms
  <img src="https://raw.githubusercontent.com/ritchieng/machine-learning-stanford/master/w6_ml_design/reg_param.png" alt="" /></li>
      <li><strong>Steps</strong>
        <ul>
          <li>Try λ in multiples of 2 on J(θ)
            <ul>
              <li>Minimise J(θ) to get θ</li>
            </ul>
          </li>
          <li>Try λ in multiples of 2 on Jcv(θ)
            <ul>
              <li>Minimise Jcv(θ) to get θ</li>
            </ul>
          </li>
          <li>Choose lowest Jcv(θ), θ_low
            <ul>
              <li>Where θ_low is θ_5 in the example since Jcv(θ_5) is the lowest</li>
            </ul>
          </li>
          <li>Pick Jcv(θ), θ_low
            <ul>
              <li>Try for Jtest(θ_low)
  <img src="https://raw.githubusercontent.com/ritchieng/machine-learning-stanford/master/w6_ml_design/choose_param.png" alt="" /></li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
  </li>
  <li>How CV and test error vary as we vary λ?
    <ul>
      <li>Jtrain(θ)
        <ul>
          <li>Small λ
            <ul>
              <li>Regularization term is small</li>
              <li>Hypothesis fits better to the data</li>
              <li>Low Jtrain(θ)</li>
            </ul>
          </li>
          <li>Large λ
            <ul>
              <li>Regularization term is large</li>
              <li>Hypothesis does not fit well to the data</li>
              <li>High Jtrain(θ)</li>
            </ul>
          </li>
        </ul>
      </li>
      <li>Jcv(θ)
        <ul>
          <li>Large λ
            <ul>
              <li>Regularization term is large</li>
              <li>High bias (underfitting)</li>
              <li>Large Jcv(θ)</li>
            </ul>
          </li>
          <li>Small λ
            <ul>
              <li>Regularization term is small</li>
              <li>High variance (overfitting)</li>
              <li>Small Jcv(θ)
  <img src="https://raw.githubusercontent.com/ritchieng/machine-learning-stanford/master/w6_ml_design/jcv_jtest2.png" alt="" /></li>
            </ul>
          </li>
        </ul>
      </li>
      <li>For a real dataset, the graph is messier, but the general trend is similar</li>
    </ul>
  </li>
</ul>

<h3 id="c-learning-curves">2c. Learning Curves</h3>
<ul>
  <li>What is the effect of m, number of training examples, on training error?
    <ul>
      <li>For m = 1, 2, 3 in the example
        <ul>
          <li>If the training set is small</li>
          <li>Easier to fit every single training example perfectly</li>
          <li>Your training error = 0 or small</li>
        </ul>
      </li>
      <li>For m = 4, 5, 6
        <ul>
          <li>If the training set grows larger</li>
          <li>Harder to fit every single training example perfectly</li>
          <li>Your training error increases</li>
        </ul>
      </li>
      <li>In general, when m increases, training error increases</li>
    </ul>
  </li>
  <li>What is the effect of m, number of training examples, on cross validation error?
    <ul>
      <li>The more data you have, where m increases
        <ul>
          <li>Your cross validation error decreases
  <img src="https://raw.githubusercontent.com/ritchieng/machine-learning-stanford/master/w6_ml_design/learning1.png" alt="" /></li>
        </ul>
      </li>
    </ul>
  </li>
  <li>High Bias (Underfit)
    <ul>
      <li>Poor performance on both training and test sets</li>
      <li>Your cross validation error decreases, but it decreases to a high value
        <ul>
          <li>Even if you have large m, you still have a straight line with a high bias</li>
          <li>Your cross validation error would still be high</li>
        </ul>
      </li>
      <li>Your training error increases close to the level achieve from your cross validation error</li>
      <li>If a learning algorithm is suffering from high bias, getting more training data will not (by itself) help much
        <ul>
          <li>As seen from the two graphs, even with a higher m, there’s no use collecting more data to decrease your cross validation error
  <img src="https://raw.githubusercontent.com/ritchieng/machine-learning-stanford/master/w6_ml_design/learning2.png" alt="" /></li>
        </ul>
      </li>
    </ul>
  </li>
  <li>High Variance (Overfit)
    <ul>
      <li>Gap in errors where training error is low but test error is high</li>
      <li>Training error would remain small
        <ul>
          <li>This happens when you use a small λ</li>
          <li>Your training error increases with m because it becomes harder to fit your data</li>
        </ul>
      </li>
      <li>Cross validation error would remain high
        <ul>
          <li>This happens when you use a small λ</li>
        </ul>
      </li>
      <li>If a learning algorithm is suffering from high variance, getting more data is likely to help
  <img src="https://raw.githubusercontent.com/ritchieng/machine-learning-stanford/master/w6_ml_design/learning3.png" alt="" /></li>
    </ul>
  </li>
</ul>

<h3 id="d-improving-algorithm-performance">2d. Improving Algorithm Performance</h3>
<ul>
  <li>Suppose you have implemented regularized linear regression to predict housing prices
    <ul>
      <li>However, when you test your hypothesis your hypothesis on new set of houses, you find that it makes unacceptably large errors
        <ul>
          <li><strong>You can do the following</strong>
            <ul>
              <li>Get more training data
                <ul>
                  <li>Fixes high variance</li>
                </ul>
              </li>
              <li>Smaller set of features
                <ul>
                  <li>Fixes high variance
                    <ul>
                      <li>Features are too complicated</li>
                    </ul>
                  </li>
                </ul>
              </li>
              <li>Get additional features
                <ul>
                  <li>Fixes high bias
                    <ul>
                      <li>Features are too simple</li>
                    </ul>
                  </li>
                </ul>
              </li>
              <li>Try adding polynomial features
                <ul>
                  <li>Fixes high bias
                    <ul>
                      <li>Too low d</li>
                    </ul>
                  </li>
                </ul>
              </li>
              <li>Try decreasing lambda
                <ul>
                  <li>Fixes high bias
                    <ul>
                      <li>Because you would have a smaller regularized term, giving more importance to other features</li>
                    </ul>
                  </li>
                </ul>
              </li>
              <li>Try increasing lambda
                <ul>
                  <li>Fixes high variance
                    <ul>
                      <li>Because you would have a larger regularized term, giving less importance to other features</li>
                    </ul>
                  </li>
                </ul>
              </li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Neural Networks and Overfitting
    <ul>
      <li>If you are fitting a neural network, you can use a small or large neural network
  <img src="https://raw.githubusercontent.com/ritchieng/machine-learning-stanford/master/w6_ml_design/nn_overfit.png" alt="" />
        <ul>
          <li>Small neural network
            <ul>
              <li>1 hidden layer</li>
              <li>1 input layer</li>
              <li>1 output layer
                <ul>
                  <li>Computationally cheaper</li>
                </ul>
              </li>
            </ul>
          </li>
          <li>Large neural network
            <ul>
              <li>Multiple hidden layers</li>
              <li>1 input layer</li>
              <li>1 output layer
                <ul>
                  <li>Computationally expensive</li>
                </ul>
              </li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
  </li>
</ul>


<div class="tags">
    
    <b>Tags: </b>
    
    
    
    <a href="/tag_machine_learning" class="btn btn-default navbar-btn cursorNorm" role="button">machine_learning</a>
    
    
    
</div>
    <!--<div>

    <a href="http://facebook.com/sharer.php?u=http://www.ritchieng.com/applying-machine-learning/" rel="nofollow" target="_blank" title="Share on Facebook" style="color:#fff; background:#3b5998; padding: 6px; text-decoration: none;">Facebook</a>

    <a href="http://twitter.com/intent/tweet?text=Applying Machine Learning&url=http://www.ritchieng.com/applying-machine-learning/&via=&related=" rel="nofollow" target="_blank" title="Share on Twitter" style="color:#fff; background:#00aced; padding: 6px; text-decoration: none;">Twitter</a>

    <a href="http://plus.google.com/share?url=http://www.ritchieng.com/applying-machine-learning/" rel="nofollow" target="_blank" title="Share on Google+" style="color:#fff; background:#dd4b39; padding: 6px; text-decoration: none;">Google+</a>

</div>-->
    <br />
<br />
<div id="disqus_thread"></div>
<script>
    /**
     *  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
     *  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables
     */
    /*
     var disqus_config = function () {
     this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
     this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
     };
     */
    (function() {  // DON'T EDIT BELOW THIS LINE
        var d = document, s = d.createElement('script');

        s.src = '//ritchieng.disqus.com/embed.js';

        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>


</div>

<hr class="shaded"/>

<footer>
            <div class="row">
                <div class="col-lg-12 footer">
               &copy; 2018 Ritchie Ng. All rights reserved. <br />
 Site last updated: Oct 29, 2018 <br />
                    <a href="https://github.com/ritchieng">Github</a> | <a href="https://www.linkedin.com/in/ritchieng">Linkedin</a> | <a href="https://www.facebook.com/ritchiengz">Facebook</a> | <a href="https://twitter.com/ritchieng">Twitter</a> | <a href="https://www.techinasia.com/profile/ritchieng">Tech in Asia</a>
<!--<p><img src="http://res.cloudinary.com/ritchieng/image/upload/v1468818828/ritchieng.com/company_logo_p3uvgl.png" alt="Ritchie Ng"/></p>-->
                </div>
            </div>
</footer>

    </div>
    <!-- /.row -->
</div>
<!-- /.container -->
    </div>
    <script>
    jQuery(function ($) {
        $('.post-content').annotator()
                .annotator('setupPlugins', {tokenUrl: 'http://example.com/api/token'})
    });
    </script>
</body>
<script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
                (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
            m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-79887611-1', 'auto');
    ga('send', 'pageview');

</script>
</html>